# fly.toml app configuration file generated for beluga-ollama on 2024-04-12T22:30:48-06:00
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = 'beluga-ollama'
primary_region = 'sjc'

[build]
  image = 'ollama/ollama'

[[mounts]]
  source = 'models'
  destination = '/home/llamacpp'
  initial_size = '75gb'

[http_service]
  internal_port = 11434
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0
  processes = ['app']

[[vm]]
  size = 'a100-80gb'
  memory = '32gb'
  cpu_kind = 'performance'
  cpus = 8
